# ===========================================
# Docker Environment Configuration
# Copy to .env and fill in your values
# ===========================================

# Server
NODE_ENV=development
PORT=3000

# Docker Group ID (run: getent group docker | cut -d: -f3)
DOCKER_GROUP_ID=999

# ===========================================
# SELF-HOSTED SERVICES (Docker)
# ===========================================

# Redis (Docker service)
REDIS_HOST=redis
REDIS_PORT=6379

# Lightpanda (Docker service)
LIGHTPANDA_WS_ENDPOINT=ws://lightpanda:9222

# -----------------------------------------
# Coder - Sandboxed Execution Environment
# Docs: https://coder.com/docs/install/docker
# -----------------------------------------
CODER_API_URL=http://coder:7080

# Admin credentials (created on first run)
CODER_ADMIN_EMAIL=admin@localhost
CODER_ADMIN_USERNAME=admin
CODER_ADMIN_PASSWORD=changeme123

# API Token - GENERATE AFTER FIRST RUN:
# 1. Start services: docker-compose up -d
# 2. Open http://localhost:7080 and login with admin credentials
# 3. Go to: Settings > Tokens > Create Token
# 4. Or via CLI: docker exec -it <coder-container> coder tokens create --name ocp-token --lifetime 8760h
# 5. Paste the token below:
CODER_API_TOKEN=

# Template ID - CREATE AFTER FIRST RUN:
# 1. Login to Coder UI at http://localhost:7080
# 2. Go to Templates > Create Template
# 3. Use "Docker" starter template for sandboxed execution
# 4. Copy the template ID from URL: /templates/<TEMPLATE_ID>
CODER_TEMPLATE_ID=

# ===========================================
# CLOUD SERVICES (Required)
# ===========================================

# PagerDuty (Cloud - or use OneUptime locally)
PAGERDUTY_API_KEY=
PAGERDUTY_WEBHOOK_SECRET=
PAGERDUTY_SERVICE_ID=
# For local OneUptime: PAGERDUTY_API_URL=http://oneuptime:3400/api

# Sanity (Cloud - Content Lake is cloud-only)
SANITY_PROJECT_ID=
SANITY_DATASET=production
SANITY_TOKEN=

# LLM Provider (anthropic or gemini)
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-sonnet-4-20250514

# Alternative: Gemini
# LLM_PROVIDER=gemini
# GEMINI_API_KEY=
# GEMINI_MODEL=gemini-1.5-pro-latest

# Slack (Cloud - or use Mattermost locally)
SLACK_BOT_TOKEN=
SLACK_APPROVAL_CHANNEL=incident-approvals
# For local Mattermost: SLACK_API_URL=http://mattermost:8065/api/v4

# ===========================================
# OPTIONAL SERVICES
# ===========================================

# Skyflow - Leave empty for local regex fallback
SKYFLOW_VAULT_ID=
SKYFLOW_VAULT_URL=
SKYFLOW_BEARER_TOKEN=

# Parallel - Web research (optional)
PARALLEL_API_KEY=

# Postman - API testing (optional)
POSTMAN_API_KEY=

# ===========================================
# CONFIDENCE THRESHOLDS
# ===========================================
CONFIDENCE_AUTO_EXECUTE_THRESHOLD=90
CONTEXT_MATCH_THRESHOLD=85
